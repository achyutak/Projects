{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Project",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4danMPXQRuviypfc7oB/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achyutak/Projects/blob/main/Text_Generation_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CENoT4h9toaA"
      },
      "source": [
        "## Importing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnVAJQfOr1x2"
      },
      "source": [
        "from keras.utils.data_utils import get_file\r\n",
        "path = get_file('shakespeare.txt',\r\n",
        "                origin = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TroNwASysXqY",
        "outputId": "13cebc18-d7f2-4874-ecdd-ffea9bad9700"
      },
      "source": [
        "with open(path, encoding='utf-8') as f:\r\n",
        "  text = f.read().lower()\r\n",
        "print('Length of Text: {} characters'.format(len(text)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btbVFrCl9K1U"
      },
      "source": [
        "## Creating a list of sentences from data taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3GyF6YetMkH",
        "outputId": "e1a604cf-3e26-4e36-d827-e39d8c00b133"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first citizen:\n",
            "before we proceed any further, hear me speak.\n",
            "\n",
            "all:\n",
            "speak, speak.\n",
            "\n",
            "first citizen:\n",
            "you are all resolved rather to die than to famish?\n",
            "\n",
            "all:\n",
            "resolved. resolved.\n",
            "\n",
            "first citizen:\n",
            "first, you know caius marcius is chief enemy to the people.\n",
            "\n",
            "all:\n",
            "we know't, we know't.\n",
            "\n",
            "first citizen:\n",
            "let us kill him, and we'll have corn at our own price.\n",
            "is't a verdict?\n",
            "\n",
            "all:\n",
            "no more talking on't; let it be done: away, away!\n",
            "\n",
            "second citizen:\n",
            "one word, good citizens.\n",
            "\n",
            "first citizen:\n",
            "we are accounted poor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNgkCnlMtWdq"
      },
      "source": [
        "data = text[:5000]\r\n",
        "# Taking only the first 5000 characters for building the model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E9GZ_tmtgYS"
      },
      "source": [
        "# print(data)\r\n",
        "# # The data we are taking to build the model."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgpXmIqItje9"
      },
      "source": [
        "# # Understanding the data\r\n",
        "# data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dnS8m608JC9"
      },
      "source": [
        "#We see that all the lines are separated by a '\\n'.\r\n",
        "# Now we split the data into lines and create a corpus.\r\n",
        "corpus = data.split('\\n')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3yBalm48xpK",
        "outputId": "a59e345f-3fcd-4a2b-9078-e68839187f97"
      },
      "source": [
        "corpus[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first citizen:',\n",
              " 'before we proceed any further, hear me speak.',\n",
              " '',\n",
              " 'all:',\n",
              " 'speak, speak.',\n",
              " '',\n",
              " 'first citizen:',\n",
              " 'you are all resolved rather to die than to famish?',\n",
              " '',\n",
              " 'all:']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z27OoIJkDwCK"
      },
      "source": [
        "The text still has a lot of punctuation marks and blank spaces. So, we use Tokenizer from keras to remove all the unnecessary pronunciation marks and create a dictionary of most frequent words in the datset.\r\n",
        "\r\n",
        "[Tokenizer:](https://keras.io/api/preprocessing/text/#tokenizer-class)\r\n",
        "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIrtgcFZFGz8"
      },
      "source": [
        "## Using Tokenizer class from tf.keras.preprocessing.text.Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyzqlsJgDuOi"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "tk = Tokenizer(num_words=500, oov_token='<OOV>') #Only the most common num_words - 1 (499 here) words are kept. \r\n",
        "# Any words that are not available in the vocabulary during sequence to text calls are given as <OOV>\r\n",
        "tk.fit_on_texts(corpus)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CROSDZsIunc0",
        "outputId": "f44916ad-9344-4858-9fc5-bf61ec37b880"
      },
      "source": [
        "# Total number of words in the corpus:\r\n",
        "print('Total Number of words in the corpus:',len(tk.word_index))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of words in the corpus: 386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbd1w5FZz7Vc",
        "outputId": "a1a549db-5212-499e-b3ac-e6006459808b"
      },
      "source": [
        "total_words = len(tk.word_index) + 1\r\n",
        "print('Number of words after considering the padding:',total_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words after considering the padding: 387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upI4sdyDABTH",
        "outputId": "4223256b-9c96-452a-8be8-a119b4249d5b"
      },
      "source": [
        "for line in corpus:\r\n",
        "  tokens_list = tk.texts_to_sequences([line])[0]\r\n",
        "  print(line)\r\n",
        "  print(tokens_list)\r\n",
        "  break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first citizen:\n",
            "[6, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov1JUXNeBAx2"
      },
      "source": [
        "sequences = []\r\n",
        "for line in corpus:\r\n",
        "  tokens_list = tk.texts_to_sequences([line])[0]\r\n",
        "  for i in range(1,len(tokens_list)):\r\n",
        "    sequences.append(tokens_list[:i+1]) \r\n",
        "# The second for loop ranges from 1 to the length of the tokens list and appends the list of sequences of variable length (2 to max_sequence_length) generated from the tokens_list \r\n",
        "# print(sequences)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2y_LxgKByAR",
        "outputId": "a6446949-c6f7-44cc-df72-87920e0d75ff"
      },
      "source": [
        "max_sequence_length = max([len(x) for x in sequences])\r\n",
        "print('Maximum length of sequences in the corpus:',max_sequence_length)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length of sequences in the corpus: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3aNBkGvDYW0"
      },
      "source": [
        "## Padding the sequences generated to maintain the uniformity in the dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmgdWC8lC4DJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "padded_sequences = pad_sequences(sequences,padding='pre')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgDFhOEkEGQF",
        "outputId": "64503b44-4125-4a0d-e5be-73e51ef061cf"
      },
      "source": [
        "print(padded_sequences[:5])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   6   4]\n",
            " [  0   0   0   0   0   0   0   0   0   0 133  10]\n",
            " [  0   0   0   0   0   0   0   0   0 133  10  71]\n",
            " [  0   0   0   0   0   0   0   0 133  10  71  72]\n",
            " [  0   0   0   0   0   0   0 133  10  71  72 134]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFdndg2hEH1l",
        "outputId": "73db4662-c8ab-411d-ecb6-c2d1bd554efb"
      },
      "source": [
        "padded_sequences.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(748, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24kb6HY6EWI2"
      },
      "source": [
        "We take the last column in each sequence as the label and use the rest of the columns as inputs to predict the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnSQC4qVHp2V"
      },
      "source": [
        "## Separating the X and the y from sequences for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdOPCHBkHHWx",
        "outputId": "a7c6a328-133a-42f8-d082-cfb3046de414"
      },
      "source": [
        "y = padded_sequences[:,-1] #Assigns the last value in each sequence to the y\r\n",
        "X = padded_sequences[:,:-1] #Assigns all but the last value from each sequence to X\r\n",
        "i = 2\r\n",
        "print(padded_sequences[i],X[i],y[i])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0 133  10  71] [  0   0   0   0   0   0   0   0   0 133  10] 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plWHfb-FIci6",
        "outputId": "d267ec88-6e3d-4e15-9e9b-09843e09666d"
      },
      "source": [
        "print(type(padded_sequences),type(X),type(y))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWLFDBI0J48k",
        "outputId": "04d6182a-f1f9-4a38-e1b8-ceb9103ecc1d"
      },
      "source": [
        "max(y) #There are 386 tokens in the dictionary that were generated from the corpus"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE1tlLtyJ-Hp"
      },
      "source": [
        "Here, we encode the labels (Just 'y') using one-hot encoding for easier training of ML Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcflThS9KsuH"
      },
      "source": [
        "## Using to_categorical from keras to one-hot-encode the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPZ3ymWIK0OQ"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjrVg8nDLCnu"
      },
      "source": [
        "Y = to_categorical(y)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sxBN08WLF1E",
        "outputId": "8d3671db-26dc-48ed-fe8e-007e69626367"
      },
      "source": [
        "print('After one hot encoding, the final shapes of the inputs and labels are:\\nX(inputs)\\t:\\t{}\\nY(labels)\\t:\\t{}'.format(X.shape,Y.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After one hot encoding, the final shapes of the inputs and labels are:\n",
            "X(inputs)\t:\t(748, 11)\n",
            "Y(labels)\t:\t(748, 387)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXW0ubKCLled"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lS7ths2MG67"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY8Dyc8oOSAU",
        "outputId": "f180e992-b0a6-4bc6-eed9-88e2f7ea63ab"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words,16,input_length=X.shape[1],mask_zero=True)) \r\n",
        "#Since we have already pre-padded the sequences with 0, mask_zero must be kept True or else, the Embedding layer will consider the 0 as input.\r\n",
        "model.add(LSTM(64))\r\n",
        "model.add(Dense(128,activation='relu'))\r\n",
        "model.add(Dropout(0.4))\r\n",
        "model.add(Dense(256,activation='relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Dense(Y.shape[1],activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 11, 16)            6192      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                20736     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 387)               99459     \n",
            "=================================================================\n",
            "Total params: 167,731\n",
            "Trainable params: 167,731\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlAjs8bnSJjA",
        "outputId": "cd9b4d0f-be1f-4ffd-c48b-de1bdb957ee7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
        "epochs = 500\r\n",
        "batch_size = 256\r\n",
        "history = model.fit(X,Y,epochs=epochs,batch_size = batch_size,validation_split=0.1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "3/3 [==============================] - 5s 657ms/step - loss: 5.9580 - accuracy: 0.0106 - val_loss: 5.9560 - val_accuracy: 0.0800\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.9533 - accuracy: 0.0445 - val_loss: 5.9527 - val_accuracy: 0.0800\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 5.9471 - accuracy: 0.0431 - val_loss: 5.9483 - val_accuracy: 0.0800\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 5.9376 - accuracy: 0.0470 - val_loss: 5.9417 - val_accuracy: 0.0800\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.9223 - accuracy: 0.0443 - val_loss: 5.9323 - val_accuracy: 0.0800\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 5.8985 - accuracy: 0.0480 - val_loss: 5.9189 - val_accuracy: 0.0800\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 5.8611 - accuracy: 0.0514 - val_loss: 5.9008 - val_accuracy: 0.0800\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.7955 - accuracy: 0.0504 - val_loss: 5.8812 - val_accuracy: 0.0800\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 5.6824 - accuracy: 0.0521 - val_loss: 5.8771 - val_accuracy: 0.0800\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 5.5753 - accuracy: 0.0460 - val_loss: 5.9702 - val_accuracy: 0.0800\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 5.5211 - accuracy: 0.0524 - val_loss: 6.0757 - val_accuracy: 0.0800\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 5.4638 - accuracy: 0.0489 - val_loss: 6.0778 - val_accuracy: 0.0800\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 5.4175 - accuracy: 0.0396 - val_loss: 6.0731 - val_accuracy: 0.0800\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5.4477 - accuracy: 0.0448 - val_loss: 6.0926 - val_accuracy: 0.0800\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.4389 - accuracy: 0.0325 - val_loss: 6.1442 - val_accuracy: 0.0533\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 5.3626 - accuracy: 0.0347 - val_loss: 6.2281 - val_accuracy: 0.0800\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 5.3874 - accuracy: 0.0346 - val_loss: 6.3098 - val_accuracy: 0.0800\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 5.3520 - accuracy: 0.0396 - val_loss: 6.3726 - val_accuracy: 0.0800\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.3613 - accuracy: 0.0447 - val_loss: 6.3976 - val_accuracy: 0.0800\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 5.3103 - accuracy: 0.0504 - val_loss: 6.4066 - val_accuracy: 0.0800\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.3138 - accuracy: 0.0511 - val_loss: 6.3991 - val_accuracy: 0.0800\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 5.3005 - accuracy: 0.0507 - val_loss: 6.3912 - val_accuracy: 0.0800\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.2847 - accuracy: 0.0443 - val_loss: 6.3919 - val_accuracy: 0.0800\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 5.2995 - accuracy: 0.0497 - val_loss: 6.3937 - val_accuracy: 0.0800\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.2538 - accuracy: 0.0509 - val_loss: 6.4088 - val_accuracy: 0.0800\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 5.2343 - accuracy: 0.0445 - val_loss: 6.4100 - val_accuracy: 0.0800\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 5.2213 - accuracy: 0.0443 - val_loss: 6.3980 - val_accuracy: 0.0800\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 5.1939 - accuracy: 0.0492 - val_loss: 6.3660 - val_accuracy: 0.0800\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 5.1695 - accuracy: 0.0462 - val_loss: 6.3164 - val_accuracy: 0.0800\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.1456 - accuracy: 0.0529 - val_loss: 6.2677 - val_accuracy: 0.0667\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 5.1199 - accuracy: 0.0533 - val_loss: 6.2175 - val_accuracy: 0.0933\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 5.1336 - accuracy: 0.0487 - val_loss: 6.1608 - val_accuracy: 0.0933\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 5.0676 - accuracy: 0.0561 - val_loss: 6.1235 - val_accuracy: 0.0933\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 5.0327 - accuracy: 0.0536 - val_loss: 6.0870 - val_accuracy: 0.0933\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.9979 - accuracy: 0.0678 - val_loss: 6.0488 - val_accuracy: 0.0933\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 4.9824 - accuracy: 0.0448 - val_loss: 6.0228 - val_accuracy: 0.0933\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 4.9643 - accuracy: 0.0605 - val_loss: 6.0011 - val_accuracy: 0.0933\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.9353 - accuracy: 0.0495 - val_loss: 5.9814 - val_accuracy: 0.1067\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.8779 - accuracy: 0.0600 - val_loss: 5.9836 - val_accuracy: 0.0933\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 4.8467 - accuracy: 0.0693 - val_loss: 5.9840 - val_accuracy: 0.0933\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.8541 - accuracy: 0.0590 - val_loss: 5.9671 - val_accuracy: 0.0933\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 4.8395 - accuracy: 0.0603 - val_loss: 5.9744 - val_accuracy: 0.0933\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.7927 - accuracy: 0.0659 - val_loss: 5.9862 - val_accuracy: 0.0800\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 4.7999 - accuracy: 0.0602 - val_loss: 5.9942 - val_accuracy: 0.0800\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.7658 - accuracy: 0.0625 - val_loss: 6.0237 - val_accuracy: 0.0667\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.7104 - accuracy: 0.0799 - val_loss: 6.0642 - val_accuracy: 0.0800\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 4.7303 - accuracy: 0.0691 - val_loss: 6.1076 - val_accuracy: 0.0667\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 4.7002 - accuracy: 0.0620 - val_loss: 6.1622 - val_accuracy: 0.0533\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.6346 - accuracy: 0.0608 - val_loss: 6.2154 - val_accuracy: 0.0533\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 4.6114 - accuracy: 0.0733 - val_loss: 6.2927 - val_accuracy: 0.0667\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 4.5578 - accuracy: 0.0767 - val_loss: 6.3948 - val_accuracy: 0.0533\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.5816 - accuracy: 0.0826 - val_loss: 6.4730 - val_accuracy: 0.0533\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.5728 - accuracy: 0.0669 - val_loss: 6.5761 - val_accuracy: 0.0533\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.5408 - accuracy: 0.0740 - val_loss: 6.7461 - val_accuracy: 0.0533\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.4704 - accuracy: 0.0801 - val_loss: 6.8944 - val_accuracy: 0.0667\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 4.4386 - accuracy: 0.0816 - val_loss: 7.0506 - val_accuracy: 0.0533\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 4.3764 - accuracy: 0.0922 - val_loss: 7.2513 - val_accuracy: 0.0667\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 4.3631 - accuracy: 0.0828 - val_loss: 7.3910 - val_accuracy: 0.0533\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.3403 - accuracy: 0.0715 - val_loss: 7.5419 - val_accuracy: 0.0400\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.3380 - accuracy: 0.0755 - val_loss: 7.7259 - val_accuracy: 0.0533\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.3350 - accuracy: 0.0767 - val_loss: 7.7884 - val_accuracy: 0.0667\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 4.3068 - accuracy: 0.0799 - val_loss: 7.8841 - val_accuracy: 0.0667\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2968 - accuracy: 0.0795 - val_loss: 8.0450 - val_accuracy: 0.0667\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.2541 - accuracy: 0.0768 - val_loss: 8.2505 - val_accuracy: 0.0267\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 4.2143 - accuracy: 0.0875 - val_loss: 8.4021 - val_accuracy: 0.0267\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.2457 - accuracy: 0.0853 - val_loss: 8.5217 - val_accuracy: 0.0267\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 4.2073 - accuracy: 0.0794 - val_loss: 8.6517 - val_accuracy: 0.0267\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.1364 - accuracy: 0.0880 - val_loss: 8.8642 - val_accuracy: 0.0267\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 4.1593 - accuracy: 0.0924 - val_loss: 8.9808 - val_accuracy: 0.0533\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.1109 - accuracy: 0.0809 - val_loss: 9.1031 - val_accuracy: 0.0533\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 4.1597 - accuracy: 0.0743 - val_loss: 9.2121 - val_accuracy: 0.0533\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 4.0901 - accuracy: 0.0959 - val_loss: 9.3788 - val_accuracy: 0.0533\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.0060 - accuracy: 0.0821 - val_loss: 9.6282 - val_accuracy: 0.0533\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 4.0552 - accuracy: 0.0991 - val_loss: 9.7349 - val_accuracy: 0.0533\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 4.0016 - accuracy: 0.1148 - val_loss: 9.7575 - val_accuracy: 0.0400\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.9769 - accuracy: 0.1079 - val_loss: 9.9626 - val_accuracy: 0.0400\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.9320 - accuracy: 0.1096 - val_loss: 10.2472 - val_accuracy: 0.0533\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.9933 - accuracy: 0.1060 - val_loss: 10.3823 - val_accuracy: 0.0400\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.9653 - accuracy: 0.1028 - val_loss: 10.5198 - val_accuracy: 0.0400\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 3.9558 - accuracy: 0.1121 - val_loss: 10.5943 - val_accuracy: 0.0533\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.8450 - accuracy: 0.1145 - val_loss: 10.7938 - val_accuracy: 0.0533\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.9413 - accuracy: 0.1025 - val_loss: 10.9700 - val_accuracy: 0.0400\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 3.8717 - accuracy: 0.1173 - val_loss: 11.1317 - val_accuracy: 0.0400\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.8119 - accuracy: 0.1187 - val_loss: 11.2629 - val_accuracy: 0.0400\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.8747 - accuracy: 0.1146 - val_loss: 11.3849 - val_accuracy: 0.0267\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.7591 - accuracy: 0.1438 - val_loss: 11.5691 - val_accuracy: 0.0267\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 3.7814 - accuracy: 0.1288 - val_loss: 11.5738 - val_accuracy: 0.0400\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.8056 - accuracy: 0.1271 - val_loss: 11.8702 - val_accuracy: 0.0533\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 3.7540 - accuracy: 0.1227 - val_loss: 12.0375 - val_accuracy: 0.0533\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.6891 - accuracy: 0.1397 - val_loss: 12.1225 - val_accuracy: 0.0533\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 3.6699 - accuracy: 0.1348 - val_loss: 12.2852 - val_accuracy: 0.0533\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 3.6988 - accuracy: 0.1429 - val_loss: 12.4292 - val_accuracy: 0.0400\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.5880 - accuracy: 0.1541 - val_loss: 12.6910 - val_accuracy: 0.0400\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 3.6261 - accuracy: 0.1421 - val_loss: 12.7813 - val_accuracy: 0.0400\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 3.5746 - accuracy: 0.1463 - val_loss: 12.9725 - val_accuracy: 0.0400\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.5632 - accuracy: 0.1598 - val_loss: 13.1100 - val_accuracy: 0.0533\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.6151 - accuracy: 0.1481 - val_loss: 13.3070 - val_accuracy: 0.0533\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.5723 - accuracy: 0.1400 - val_loss: 13.5892 - val_accuracy: 0.0533\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.4475 - accuracy: 0.1799 - val_loss: 13.6953 - val_accuracy: 0.0533\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.5058 - accuracy: 0.1544 - val_loss: 13.9916 - val_accuracy: 0.0533\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 3.4507 - accuracy: 0.1583 - val_loss: 13.9316 - val_accuracy: 0.0533\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 3.4154 - accuracy: 0.1930 - val_loss: 14.2234 - val_accuracy: 0.0533\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.3910 - accuracy: 0.1831 - val_loss: 14.1871 - val_accuracy: 0.0533\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 3.3156 - accuracy: 0.1775 - val_loss: 14.2206 - val_accuracy: 0.0533\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 3.3739 - accuracy: 0.1728 - val_loss: 14.3426 - val_accuracy: 0.0533\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.3916 - accuracy: 0.1596 - val_loss: 14.3667 - val_accuracy: 0.0533\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.3151 - accuracy: 0.1844 - val_loss: 14.4775 - val_accuracy: 0.0533\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 3.3185 - accuracy: 0.1864 - val_loss: 14.7466 - val_accuracy: 0.0533\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 3.3273 - accuracy: 0.1546 - val_loss: 14.8905 - val_accuracy: 0.0533\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 3.2613 - accuracy: 0.1756 - val_loss: 15.0558 - val_accuracy: 0.0533\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 3.2447 - accuracy: 0.1866 - val_loss: 15.1576 - val_accuracy: 0.0533\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 3.2514 - accuracy: 0.1802 - val_loss: 15.3851 - val_accuracy: 0.0533\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 3.1782 - accuracy: 0.2060 - val_loss: 15.6173 - val_accuracy: 0.0533\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 3.1283 - accuracy: 0.2217 - val_loss: 15.7406 - val_accuracy: 0.0533\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 3.1151 - accuracy: 0.2117 - val_loss: 15.9067 - val_accuracy: 0.0533\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 3.0209 - accuracy: 0.2230 - val_loss: 16.1767 - val_accuracy: 0.0533\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 3.1364 - accuracy: 0.1924 - val_loss: 16.1767 - val_accuracy: 0.0533\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 3.0405 - accuracy: 0.2205 - val_loss: 16.5005 - val_accuracy: 0.0533\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 3.1095 - accuracy: 0.1816 - val_loss: 16.6261 - val_accuracy: 0.0533\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 2.9975 - accuracy: 0.2144 - val_loss: 16.6293 - val_accuracy: 0.0533\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 2.9940 - accuracy: 0.2186 - val_loss: 16.6659 - val_accuracy: 0.0533\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.9540 - accuracy: 0.2243 - val_loss: 16.8764 - val_accuracy: 0.0533\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.9161 - accuracy: 0.2235 - val_loss: 17.0715 - val_accuracy: 0.0533\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.9812 - accuracy: 0.2203 - val_loss: 17.1506 - val_accuracy: 0.0533\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.9847 - accuracy: 0.2081 - val_loss: 17.2191 - val_accuracy: 0.0533\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.9180 - accuracy: 0.2542 - val_loss: 17.6619 - val_accuracy: 0.0533\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.9364 - accuracy: 0.2226 - val_loss: 17.4222 - val_accuracy: 0.0533\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.8271 - accuracy: 0.2586 - val_loss: 17.4988 - val_accuracy: 0.0533\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.8705 - accuracy: 0.2370 - val_loss: 17.6699 - val_accuracy: 0.0533\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.8219 - accuracy: 0.2478 - val_loss: 17.8989 - val_accuracy: 0.0533\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 2.7874 - accuracy: 0.2304 - val_loss: 17.9485 - val_accuracy: 0.0533\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.7914 - accuracy: 0.2547 - val_loss: 17.7936 - val_accuracy: 0.0533\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.7420 - accuracy: 0.2668 - val_loss: 18.1768 - val_accuracy: 0.0533\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.7576 - accuracy: 0.2603 - val_loss: 18.3076 - val_accuracy: 0.0533\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.8490 - accuracy: 0.2425 - val_loss: 18.4931 - val_accuracy: 0.0533\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.7269 - accuracy: 0.2511 - val_loss: 18.6708 - val_accuracy: 0.0533\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.7395 - accuracy: 0.2589 - val_loss: 18.5310 - val_accuracy: 0.0533\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.6548 - accuracy: 0.2868 - val_loss: 18.7489 - val_accuracy: 0.0533\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.7237 - accuracy: 0.2787 - val_loss: 18.7474 - val_accuracy: 0.0533\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.7103 - accuracy: 0.2449 - val_loss: 18.8428 - val_accuracy: 0.0533\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.5335 - accuracy: 0.2927 - val_loss: 19.1565 - val_accuracy: 0.0533\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.6001 - accuracy: 0.2897 - val_loss: 19.0883 - val_accuracy: 0.0533\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.6082 - accuracy: 0.2924 - val_loss: 19.1936 - val_accuracy: 0.0533\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.5256 - accuracy: 0.2867 - val_loss: 19.3014 - val_accuracy: 0.0533\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 2.4445 - accuracy: 0.3297 - val_loss: 19.3960 - val_accuracy: 0.0533\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.5067 - accuracy: 0.2843 - val_loss: 19.8464 - val_accuracy: 0.0533\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.4774 - accuracy: 0.3243 - val_loss: 19.9737 - val_accuracy: 0.0533\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 2.4763 - accuracy: 0.3042 - val_loss: 20.1795 - val_accuracy: 0.0533\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 2.4647 - accuracy: 0.2941 - val_loss: 20.3150 - val_accuracy: 0.0533\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.4819 - accuracy: 0.3374 - val_loss: 20.4531 - val_accuracy: 0.0533\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.4188 - accuracy: 0.2936 - val_loss: 20.7354 - val_accuracy: 0.0533\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.4582 - accuracy: 0.3137 - val_loss: 20.8838 - val_accuracy: 0.0533\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 2.4203 - accuracy: 0.3137 - val_loss: 20.9331 - val_accuracy: 0.0533\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.3772 - accuracy: 0.3189 - val_loss: 21.0176 - val_accuracy: 0.0533\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.4140 - accuracy: 0.3261 - val_loss: 21.0619 - val_accuracy: 0.0533\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 2.3826 - accuracy: 0.3189 - val_loss: 21.3030 - val_accuracy: 0.0533\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.2891 - accuracy: 0.3407 - val_loss: 21.3669 - val_accuracy: 0.0533\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.2827 - accuracy: 0.3519 - val_loss: 21.4843 - val_accuracy: 0.0533\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.3462 - accuracy: 0.3447 - val_loss: 21.5714 - val_accuracy: 0.0533\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.2827 - accuracy: 0.3533 - val_loss: 21.5640 - val_accuracy: 0.0533\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.2740 - accuracy: 0.3469 - val_loss: 21.5808 - val_accuracy: 0.0400\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 2.2253 - accuracy: 0.3714 - val_loss: 21.5348 - val_accuracy: 0.0400\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.2344 - accuracy: 0.3531 - val_loss: 21.6949 - val_accuracy: 0.0533\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.2197 - accuracy: 0.3401 - val_loss: 21.9213 - val_accuracy: 0.0533\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.1686 - accuracy: 0.3788 - val_loss: 21.9765 - val_accuracy: 0.0533\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.2459 - accuracy: 0.3172 - val_loss: 22.0913 - val_accuracy: 0.0533\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.2586 - accuracy: 0.3422 - val_loss: 22.2160 - val_accuracy: 0.0533\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 2.1647 - accuracy: 0.3727 - val_loss: 22.3875 - val_accuracy: 0.0533\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 2.1412 - accuracy: 0.3803 - val_loss: 22.3384 - val_accuracy: 0.0533\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 2.1378 - accuracy: 0.3880 - val_loss: 22.3709 - val_accuracy: 0.0533\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 2.1268 - accuracy: 0.3565 - val_loss: 22.5511 - val_accuracy: 0.0533\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 2.0545 - accuracy: 0.4045 - val_loss: 23.0475 - val_accuracy: 0.0533\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.1532 - accuracy: 0.3696 - val_loss: 22.9355 - val_accuracy: 0.0533\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.0818 - accuracy: 0.3905 - val_loss: 23.0760 - val_accuracy: 0.0533\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 2.1381 - accuracy: 0.3587 - val_loss: 23.3436 - val_accuracy: 0.0533\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 2.0704 - accuracy: 0.3772 - val_loss: 23.3585 - val_accuracy: 0.0400\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 2.0315 - accuracy: 0.4098 - val_loss: 23.4657 - val_accuracy: 0.0400\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 2.1315 - accuracy: 0.3590 - val_loss: 23.4087 - val_accuracy: 0.0400\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.0582 - accuracy: 0.3742 - val_loss: 23.5788 - val_accuracy: 0.0400\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 1.9991 - accuracy: 0.4124 - val_loss: 23.6653 - val_accuracy: 0.0400\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.9627 - accuracy: 0.4160 - val_loss: 23.7303 - val_accuracy: 0.0400\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 2.0702 - accuracy: 0.3966 - val_loss: 23.9813 - val_accuracy: 0.0400\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.9551 - accuracy: 0.4165 - val_loss: 24.2376 - val_accuracy: 0.0400\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.8925 - accuracy: 0.4501 - val_loss: 24.2088 - val_accuracy: 0.0400\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 2.0153 - accuracy: 0.3956 - val_loss: 24.4678 - val_accuracy: 0.0400\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.9293 - accuracy: 0.4218 - val_loss: 24.5946 - val_accuracy: 0.0400\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.9216 - accuracy: 0.4379 - val_loss: 24.4192 - val_accuracy: 0.0400\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.9116 - accuracy: 0.4297 - val_loss: 24.6706 - val_accuracy: 0.0533\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.9120 - accuracy: 0.4175 - val_loss: 24.6627 - val_accuracy: 0.0533\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.9183 - accuracy: 0.4015 - val_loss: 24.6232 - val_accuracy: 0.0533\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.8871 - accuracy: 0.4285 - val_loss: 24.6221 - val_accuracy: 0.0533\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.8940 - accuracy: 0.4263 - val_loss: 24.5850 - val_accuracy: 0.0400\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.8769 - accuracy: 0.4159 - val_loss: 24.6545 - val_accuracy: 0.0400\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.8794 - accuracy: 0.4228 - val_loss: 24.7499 - val_accuracy: 0.0400\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.8560 - accuracy: 0.4420 - val_loss: 25.1971 - val_accuracy: 0.0400\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 1.8403 - accuracy: 0.4551 - val_loss: 25.2518 - val_accuracy: 0.0400\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.7916 - accuracy: 0.4406 - val_loss: 24.9919 - val_accuracy: 0.0400\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.8073 - accuracy: 0.4512 - val_loss: 25.2799 - val_accuracy: 0.0400\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.8247 - accuracy: 0.4345 - val_loss: 25.3981 - val_accuracy: 0.0400\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.7613 - accuracy: 0.4690 - val_loss: 25.5713 - val_accuracy: 0.0400\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.7564 - accuracy: 0.4588 - val_loss: 25.8690 - val_accuracy: 0.0400\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.7118 - accuracy: 0.4802 - val_loss: 25.6610 - val_accuracy: 0.0400\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 1.7224 - accuracy: 0.4646 - val_loss: 25.8708 - val_accuracy: 0.0400\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.7130 - accuracy: 0.4659 - val_loss: 26.1447 - val_accuracy: 0.0400\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.7386 - accuracy: 0.4760 - val_loss: 25.8202 - val_accuracy: 0.0400\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.7416 - accuracy: 0.4614 - val_loss: 26.0862 - val_accuracy: 0.0400\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.6919 - accuracy: 0.4794 - val_loss: 26.5328 - val_accuracy: 0.0400\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 1.6516 - accuracy: 0.4951 - val_loss: 26.3286 - val_accuracy: 0.0400\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.6512 - accuracy: 0.4980 - val_loss: 26.4413 - val_accuracy: 0.0400\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.6936 - accuracy: 0.4775 - val_loss: 26.5775 - val_accuracy: 0.0400\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.7327 - accuracy: 0.4701 - val_loss: 26.4965 - val_accuracy: 0.0400\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.7465 - accuracy: 0.4729 - val_loss: 26.8837 - val_accuracy: 0.0533\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.6403 - accuracy: 0.4908 - val_loss: 26.8720 - val_accuracy: 0.0400\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.6329 - accuracy: 0.4814 - val_loss: 26.7185 - val_accuracy: 0.0400\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.6512 - accuracy: 0.4700 - val_loss: 26.8699 - val_accuracy: 0.0400\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.6219 - accuracy: 0.4948 - val_loss: 27.0858 - val_accuracy: 0.0400\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.6100 - accuracy: 0.5116 - val_loss: 27.2640 - val_accuracy: 0.0400\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.5748 - accuracy: 0.5269 - val_loss: 27.3003 - val_accuracy: 0.0400\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.6001 - accuracy: 0.5070 - val_loss: 27.1249 - val_accuracy: 0.0400\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.5842 - accuracy: 0.5260 - val_loss: 27.1248 - val_accuracy: 0.0400\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.5469 - accuracy: 0.5245 - val_loss: 27.4405 - val_accuracy: 0.0400\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.5669 - accuracy: 0.4997 - val_loss: 27.5814 - val_accuracy: 0.0400\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.5259 - accuracy: 0.5137 - val_loss: 27.5284 - val_accuracy: 0.0400\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.6177 - accuracy: 0.4957 - val_loss: 27.5932 - val_accuracy: 0.0400\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.5062 - accuracy: 0.5539 - val_loss: 27.9066 - val_accuracy: 0.0400\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.4793 - accuracy: 0.5177 - val_loss: 28.0840 - val_accuracy: 0.0400\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.5074 - accuracy: 0.5269 - val_loss: 27.9551 - val_accuracy: 0.0400\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1.4803 - accuracy: 0.5497 - val_loss: 27.9036 - val_accuracy: 0.0400\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.4638 - accuracy: 0.5417 - val_loss: 28.0368 - val_accuracy: 0.0533\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.4109 - accuracy: 0.5650 - val_loss: 28.0864 - val_accuracy: 0.0400\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.5090 - accuracy: 0.5178 - val_loss: 28.0392 - val_accuracy: 0.0400\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.4934 - accuracy: 0.5412 - val_loss: 28.1063 - val_accuracy: 0.0400\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.4164 - accuracy: 0.5478 - val_loss: 28.2124 - val_accuracy: 0.0400\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.3549 - accuracy: 0.5712 - val_loss: 28.2377 - val_accuracy: 0.0400\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.4116 - accuracy: 0.5638 - val_loss: 28.2929 - val_accuracy: 0.0400\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.3710 - accuracy: 0.6012 - val_loss: 28.3823 - val_accuracy: 0.0400\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.4067 - accuracy: 0.5817 - val_loss: 28.5160 - val_accuracy: 0.0400\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.3341 - accuracy: 0.5849 - val_loss: 28.6921 - val_accuracy: 0.0400\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.3729 - accuracy: 0.5690 - val_loss: 28.7569 - val_accuracy: 0.0400\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.3577 - accuracy: 0.5610 - val_loss: 28.7029 - val_accuracy: 0.0400\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.2979 - accuracy: 0.5999 - val_loss: 28.9001 - val_accuracy: 0.0400\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.3112 - accuracy: 0.5865 - val_loss: 28.9615 - val_accuracy: 0.0400\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.3693 - accuracy: 0.5526 - val_loss: 29.0654 - val_accuracy: 0.0400\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.3685 - accuracy: 0.5759 - val_loss: 29.2987 - val_accuracy: 0.0400\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.4302 - accuracy: 0.5532 - val_loss: 29.4100 - val_accuracy: 0.0400\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.2889 - accuracy: 0.5938 - val_loss: 29.5815 - val_accuracy: 0.0400\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.3080 - accuracy: 0.5940 - val_loss: 29.9139 - val_accuracy: 0.0400\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.3305 - accuracy: 0.5729 - val_loss: 29.9091 - val_accuracy: 0.0400\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.3026 - accuracy: 0.5774 - val_loss: 30.0210 - val_accuracy: 0.0400\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.3428 - accuracy: 0.5767 - val_loss: 30.1502 - val_accuracy: 0.0400\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.3253 - accuracy: 0.5611 - val_loss: 29.9969 - val_accuracy: 0.0400\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.3095 - accuracy: 0.5918 - val_loss: 30.1265 - val_accuracy: 0.0400\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.3695 - accuracy: 0.5523 - val_loss: 30.2717 - val_accuracy: 0.0400\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.3123 - accuracy: 0.5969 - val_loss: 30.1411 - val_accuracy: 0.0400\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.2533 - accuracy: 0.5641 - val_loss: 30.1379 - val_accuracy: 0.0400\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.2686 - accuracy: 0.6043 - val_loss: 30.3067 - val_accuracy: 0.0400\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.2664 - accuracy: 0.5802 - val_loss: 30.4495 - val_accuracy: 0.0400\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.2534 - accuracy: 0.5970 - val_loss: 30.6120 - val_accuracy: 0.0400\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.2517 - accuracy: 0.6083 - val_loss: 30.5187 - val_accuracy: 0.0400\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.2553 - accuracy: 0.6034 - val_loss: 30.5339 - val_accuracy: 0.0400\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.2196 - accuracy: 0.6009 - val_loss: 30.7344 - val_accuracy: 0.0400\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.1735 - accuracy: 0.6305 - val_loss: 30.6297 - val_accuracy: 0.0400\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 1.1871 - accuracy: 0.6125 - val_loss: 30.7742 - val_accuracy: 0.0400\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.1648 - accuracy: 0.6290 - val_loss: 31.0391 - val_accuracy: 0.0400\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.1802 - accuracy: 0.6147 - val_loss: 31.0770 - val_accuracy: 0.0533\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.2129 - accuracy: 0.6056 - val_loss: 30.8853 - val_accuracy: 0.0400\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.1677 - accuracy: 0.6240 - val_loss: 30.8777 - val_accuracy: 0.0400\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.2222 - accuracy: 0.6058 - val_loss: 31.1557 - val_accuracy: 0.0400\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.1283 - accuracy: 0.6486 - val_loss: 31.2666 - val_accuracy: 0.0400\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.2203 - accuracy: 0.6164 - val_loss: 31.3292 - val_accuracy: 0.0400\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.2170 - accuracy: 0.6164 - val_loss: 31.4327 - val_accuracy: 0.0400\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 1.1970 - accuracy: 0.6186 - val_loss: 31.3734 - val_accuracy: 0.0400\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1.2053 - accuracy: 0.6214 - val_loss: 31.4825 - val_accuracy: 0.0400\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.1054 - accuracy: 0.6567 - val_loss: 31.5528 - val_accuracy: 0.0400\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.1034 - accuracy: 0.6523 - val_loss: 31.2112 - val_accuracy: 0.0400\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.1567 - accuracy: 0.6361 - val_loss: 31.1562 - val_accuracy: 0.0533\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.0664 - accuracy: 0.6555 - val_loss: 31.3434 - val_accuracy: 0.0533\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.1165 - accuracy: 0.6530 - val_loss: 31.4206 - val_accuracy: 0.0533\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.0897 - accuracy: 0.6466 - val_loss: 31.4543 - val_accuracy: 0.0400\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.1159 - accuracy: 0.6307 - val_loss: 31.6375 - val_accuracy: 0.0400\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.0710 - accuracy: 0.6695 - val_loss: 31.6814 - val_accuracy: 0.0400\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.1219 - accuracy: 0.6398 - val_loss: 31.8608 - val_accuracy: 0.0533\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.0605 - accuracy: 0.6594 - val_loss: 31.9966 - val_accuracy: 0.0533\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.1083 - accuracy: 0.6427 - val_loss: 32.1143 - val_accuracy: 0.0533\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.0919 - accuracy: 0.6387 - val_loss: 32.4058 - val_accuracy: 0.0533\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.0145 - accuracy: 0.6687 - val_loss: 32.5036 - val_accuracy: 0.0400\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.0660 - accuracy: 0.6577 - val_loss: 32.3664 - val_accuracy: 0.0400\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.0352 - accuracy: 0.6656 - val_loss: 32.4051 - val_accuracy: 0.0400\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.0010 - accuracy: 0.6584 - val_loss: 32.7989 - val_accuracy: 0.0400\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.0927 - accuracy: 0.6506 - val_loss: 32.9101 - val_accuracy: 0.0400\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.0682 - accuracy: 0.6510 - val_loss: 32.8438 - val_accuracy: 0.0400\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.0529 - accuracy: 0.6602 - val_loss: 32.9358 - val_accuracy: 0.0400\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.1082 - accuracy: 0.6319 - val_loss: 32.7160 - val_accuracy: 0.0400\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.0437 - accuracy: 0.6676 - val_loss: 32.7904 - val_accuracy: 0.0400\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.0298 - accuracy: 0.6732 - val_loss: 32.9829 - val_accuracy: 0.0400\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.9743 - accuracy: 0.6747 - val_loss: 33.0764 - val_accuracy: 0.0400\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0088 - accuracy: 0.6672 - val_loss: 33.1122 - val_accuracy: 0.0400\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.0342 - accuracy: 0.6610 - val_loss: 33.4045 - val_accuracy: 0.0400\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.0210 - accuracy: 0.6695 - val_loss: 33.4978 - val_accuracy: 0.0400\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9891 - accuracy: 0.6806 - val_loss: 33.1900 - val_accuracy: 0.0400\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.0175 - accuracy: 0.6757 - val_loss: 33.4031 - val_accuracy: 0.0400\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0464 - accuracy: 0.6723 - val_loss: 33.6151 - val_accuracy: 0.0400\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.9806 - accuracy: 0.6980 - val_loss: 33.6551 - val_accuracy: 0.0400\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.9047 - accuracy: 0.7071 - val_loss: 33.7873 - val_accuracy: 0.0400\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.9719 - accuracy: 0.7249 - val_loss: 33.6665 - val_accuracy: 0.0667\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9741 - accuracy: 0.6830 - val_loss: 33.5522 - val_accuracy: 0.0533\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.9713 - accuracy: 0.6760 - val_loss: 33.6675 - val_accuracy: 0.0533\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9160 - accuracy: 0.6966 - val_loss: 33.7490 - val_accuracy: 0.0667\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.9406 - accuracy: 0.6784 - val_loss: 33.7352 - val_accuracy: 0.0533\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.9492 - accuracy: 0.7015 - val_loss: 33.7242 - val_accuracy: 0.0400\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 0.9224 - accuracy: 0.6895 - val_loss: 33.6418 - val_accuracy: 0.0400\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.9314 - accuracy: 0.7018 - val_loss: 33.8484 - val_accuracy: 0.0533\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.9614 - accuracy: 0.7030 - val_loss: 34.0846 - val_accuracy: 0.0400\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.9105 - accuracy: 0.7115 - val_loss: 33.9903 - val_accuracy: 0.0400\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.9551 - accuracy: 0.6768 - val_loss: 34.1602 - val_accuracy: 0.0400\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8576 - accuracy: 0.7271 - val_loss: 34.3899 - val_accuracy: 0.0400\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.0307 - accuracy: 0.6605 - val_loss: 34.1413 - val_accuracy: 0.0533\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.9072 - accuracy: 0.7122 - val_loss: 34.1018 - val_accuracy: 0.0533\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.9703 - accuracy: 0.6826 - val_loss: 34.3132 - val_accuracy: 0.0533\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.9266 - accuracy: 0.7116 - val_loss: 34.3506 - val_accuracy: 0.0533\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8649 - accuracy: 0.7258 - val_loss: 34.5090 - val_accuracy: 0.0533\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8623 - accuracy: 0.7243 - val_loss: 34.6979 - val_accuracy: 0.0533\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.8999 - accuracy: 0.7032 - val_loss: 34.6646 - val_accuracy: 0.0533\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8825 - accuracy: 0.7216 - val_loss: 34.6366 - val_accuracy: 0.0533\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9301 - accuracy: 0.6935 - val_loss: 34.8312 - val_accuracy: 0.0400\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8838 - accuracy: 0.7141 - val_loss: 34.9704 - val_accuracy: 0.0400\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8289 - accuracy: 0.7189 - val_loss: 35.0032 - val_accuracy: 0.0400\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8305 - accuracy: 0.7037 - val_loss: 35.1569 - val_accuracy: 0.0400\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8743 - accuracy: 0.7018 - val_loss: 35.4782 - val_accuracy: 0.0667\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8343 - accuracy: 0.7096 - val_loss: 35.4944 - val_accuracy: 0.0667\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.8173 - accuracy: 0.7418 - val_loss: 35.2353 - val_accuracy: 0.0667\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.8580 - accuracy: 0.7055 - val_loss: 35.2394 - val_accuracy: 0.0533\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.8386 - accuracy: 0.7106 - val_loss: 35.4037 - val_accuracy: 0.0667\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.8347 - accuracy: 0.7249 - val_loss: 35.3906 - val_accuracy: 0.0667\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7363 - accuracy: 0.7652 - val_loss: 35.2433 - val_accuracy: 0.0533\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.7984 - accuracy: 0.7330 - val_loss: 35.3069 - val_accuracy: 0.0533\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.8810 - accuracy: 0.7052 - val_loss: 35.6489 - val_accuracy: 0.0533\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.7804 - accuracy: 0.7487 - val_loss: 36.0027 - val_accuracy: 0.0533\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7745 - accuracy: 0.7494 - val_loss: 36.1470 - val_accuracy: 0.0533\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.8004 - accuracy: 0.7377 - val_loss: 36.0861 - val_accuracy: 0.0667\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8181 - accuracy: 0.7077 - val_loss: 36.0736 - val_accuracy: 0.0667\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.7935 - accuracy: 0.7354 - val_loss: 36.2605 - val_accuracy: 0.0667\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8513 - accuracy: 0.7086 - val_loss: 36.2399 - val_accuracy: 0.0533\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7980 - accuracy: 0.7538 - val_loss: 36.1283 - val_accuracy: 0.0400\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8445 - accuracy: 0.7273 - val_loss: 36.1427 - val_accuracy: 0.0400\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.7804 - accuracy: 0.7342 - val_loss: 36.3955 - val_accuracy: 0.0400\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.8230 - accuracy: 0.7261 - val_loss: 36.4188 - val_accuracy: 0.0533\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.7775 - accuracy: 0.7436 - val_loss: 36.2964 - val_accuracy: 0.0400\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7656 - accuracy: 0.7566 - val_loss: 36.2503 - val_accuracy: 0.0533\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.7927 - accuracy: 0.7542 - val_loss: 36.3365 - val_accuracy: 0.0533\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.7692 - accuracy: 0.7566 - val_loss: 36.3794 - val_accuracy: 0.0533\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.7630 - accuracy: 0.7518 - val_loss: 36.4164 - val_accuracy: 0.0533\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.8431 - accuracy: 0.7325 - val_loss: 36.5386 - val_accuracy: 0.0667\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8128 - accuracy: 0.7388 - val_loss: 36.5307 - val_accuracy: 0.0667\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.7340 - accuracy: 0.7640 - val_loss: 36.4676 - val_accuracy: 0.0533\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.7608 - accuracy: 0.7777 - val_loss: 36.5429 - val_accuracy: 0.0533\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.7407 - accuracy: 0.7573 - val_loss: 36.7103 - val_accuracy: 0.0533\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7137 - accuracy: 0.7514 - val_loss: 36.6152 - val_accuracy: 0.0400\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7973 - accuracy: 0.7423 - val_loss: 36.5824 - val_accuracy: 0.0400\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6919 - accuracy: 0.7851 - val_loss: 36.8082 - val_accuracy: 0.0400\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.7475 - accuracy: 0.7595 - val_loss: 36.8853 - val_accuracy: 0.0400\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.7146 - accuracy: 0.7661 - val_loss: 36.8089 - val_accuracy: 0.0400\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.7167 - accuracy: 0.7642 - val_loss: 36.9038 - val_accuracy: 0.0533\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7009 - accuracy: 0.7494 - val_loss: 37.0650 - val_accuracy: 0.0533\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.7793 - accuracy: 0.7472 - val_loss: 37.0353 - val_accuracy: 0.0533\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.7126 - accuracy: 0.7542 - val_loss: 37.1118 - val_accuracy: 0.0400\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.7138 - accuracy: 0.7644 - val_loss: 37.2810 - val_accuracy: 0.0533\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6974 - accuracy: 0.7463 - val_loss: 37.4232 - val_accuracy: 0.0533\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7403 - accuracy: 0.7610 - val_loss: 37.3086 - val_accuracy: 0.0533\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7054 - accuracy: 0.7732 - val_loss: 37.3738 - val_accuracy: 0.0400\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 0.6849 - accuracy: 0.7732 - val_loss: 37.6970 - val_accuracy: 0.0533\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6932 - accuracy: 0.7647 - val_loss: 37.8458 - val_accuracy: 0.0667\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.6743 - accuracy: 0.7561 - val_loss: 37.7099 - val_accuracy: 0.0533\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.6748 - accuracy: 0.7667 - val_loss: 37.7893 - val_accuracy: 0.0533\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6843 - accuracy: 0.7785 - val_loss: 37.9295 - val_accuracy: 0.0533\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.7194 - accuracy: 0.7612 - val_loss: 38.0202 - val_accuracy: 0.0533\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7208 - accuracy: 0.7488 - val_loss: 38.0037 - val_accuracy: 0.0533\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.6427 - accuracy: 0.7733 - val_loss: 38.0730 - val_accuracy: 0.0533\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.6578 - accuracy: 0.7824 - val_loss: 38.1469 - val_accuracy: 0.0533\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6401 - accuracy: 0.7972 - val_loss: 37.9804 - val_accuracy: 0.0533\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.6748 - accuracy: 0.7782 - val_loss: 37.7787 - val_accuracy: 0.0400\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6344 - accuracy: 0.8033 - val_loss: 37.7660 - val_accuracy: 0.0533\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6439 - accuracy: 0.7760 - val_loss: 37.9369 - val_accuracy: 0.0533\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.6403 - accuracy: 0.7772 - val_loss: 38.1375 - val_accuracy: 0.0533\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6512 - accuracy: 0.7829 - val_loss: 38.2026 - val_accuracy: 0.0400\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6543 - accuracy: 0.7819 - val_loss: 38.4141 - val_accuracy: 0.0400\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6619 - accuracy: 0.7831 - val_loss: 38.4044 - val_accuracy: 0.0400\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.6761 - accuracy: 0.7898 - val_loss: 38.5345 - val_accuracy: 0.0400\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.6992 - accuracy: 0.7762 - val_loss: 38.5881 - val_accuracy: 0.0400\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.6261 - accuracy: 0.7816 - val_loss: 38.6443 - val_accuracy: 0.0400\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.6174 - accuracy: 0.8026 - val_loss: 38.7487 - val_accuracy: 0.0400\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6249 - accuracy: 0.7959 - val_loss: 38.8405 - val_accuracy: 0.0533\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.7031 - accuracy: 0.7751 - val_loss: 38.8163 - val_accuracy: 0.0400\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6465 - accuracy: 0.7870 - val_loss: 38.7569 - val_accuracy: 0.0400\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.6674 - accuracy: 0.7910 - val_loss: 38.7585 - val_accuracy: 0.0400\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6447 - accuracy: 0.7908 - val_loss: 38.8129 - val_accuracy: 0.0400\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6471 - accuracy: 0.7807 - val_loss: 38.7465 - val_accuracy: 0.0400\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.6809 - accuracy: 0.7703 - val_loss: 38.7155 - val_accuracy: 0.0400\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6709 - accuracy: 0.7787 - val_loss: 38.7463 - val_accuracy: 0.0400\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.6172 - accuracy: 0.8086 - val_loss: 38.9079 - val_accuracy: 0.0400\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.6268 - accuracy: 0.7974 - val_loss: 38.9517 - val_accuracy: 0.0400\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.6447 - accuracy: 0.7679 - val_loss: 38.8578 - val_accuracy: 0.0400\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5804 - accuracy: 0.8075 - val_loss: 38.8234 - val_accuracy: 0.0400\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.6041 - accuracy: 0.8018 - val_loss: 38.9910 - val_accuracy: 0.0400\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6055 - accuracy: 0.8038 - val_loss: 39.0683 - val_accuracy: 0.0400\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5746 - accuracy: 0.8041 - val_loss: 39.1786 - val_accuracy: 0.0533\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6030 - accuracy: 0.7957 - val_loss: 39.3073 - val_accuracy: 0.0533\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.6286 - accuracy: 0.7770 - val_loss: 39.3919 - val_accuracy: 0.0533\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.6018 - accuracy: 0.8160 - val_loss: 39.6961 - val_accuracy: 0.0533\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.5780 - accuracy: 0.8102 - val_loss: 39.7579 - val_accuracy: 0.0400\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5985 - accuracy: 0.7860 - val_loss: 39.7444 - val_accuracy: 0.0400\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5864 - accuracy: 0.7976 - val_loss: 39.7809 - val_accuracy: 0.0533\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5771 - accuracy: 0.7977 - val_loss: 39.8777 - val_accuracy: 0.0533\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6267 - accuracy: 0.8036 - val_loss: 39.8870 - val_accuracy: 0.0533\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5911 - accuracy: 0.8200 - val_loss: 39.8921 - val_accuracy: 0.0400\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.6154 - accuracy: 0.7571 - val_loss: 39.9766 - val_accuracy: 0.0400\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5947 - accuracy: 0.7974 - val_loss: 40.0881 - val_accuracy: 0.0533\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5544 - accuracy: 0.8289 - val_loss: 40.1025 - val_accuracy: 0.0533\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5436 - accuracy: 0.8005 - val_loss: 39.9672 - val_accuracy: 0.0533\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 0.5621 - accuracy: 0.8055 - val_loss: 39.8668 - val_accuracy: 0.0533\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5621 - accuracy: 0.8112 - val_loss: 40.1254 - val_accuracy: 0.0667\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5787 - accuracy: 0.8053 - val_loss: 40.3379 - val_accuracy: 0.0667\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5758 - accuracy: 0.7925 - val_loss: 40.2039 - val_accuracy: 0.0667\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5724 - accuracy: 0.8134 - val_loss: 40.2824 - val_accuracy: 0.0533\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.5618 - accuracy: 0.8220 - val_loss: 40.6067 - val_accuracy: 0.0533\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5759 - accuracy: 0.8129 - val_loss: 40.6023 - val_accuracy: 0.0533\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5643 - accuracy: 0.8087 - val_loss: 40.3089 - val_accuracy: 0.0533\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5628 - accuracy: 0.8178 - val_loss: 40.2787 - val_accuracy: 0.0533\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5569 - accuracy: 0.8205 - val_loss: 40.4529 - val_accuracy: 0.0533\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5074 - accuracy: 0.8300 - val_loss: 40.6619 - val_accuracy: 0.0533\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5509 - accuracy: 0.8290 - val_loss: 40.7977 - val_accuracy: 0.0533\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4876 - accuracy: 0.8428 - val_loss: 40.8745 - val_accuracy: 0.0533\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.5206 - accuracy: 0.8350 - val_loss: 40.9095 - val_accuracy: 0.0533\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5759 - accuracy: 0.8375 - val_loss: 41.0075 - val_accuracy: 0.0533\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4721 - accuracy: 0.8490 - val_loss: 41.1745 - val_accuracy: 0.0533\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5317 - accuracy: 0.8260 - val_loss: 41.2088 - val_accuracy: 0.0533\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5176 - accuracy: 0.8200 - val_loss: 41.2367 - val_accuracy: 0.0533\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5109 - accuracy: 0.8188 - val_loss: 41.4133 - val_accuracy: 0.0533\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5505 - accuracy: 0.8416 - val_loss: 41.6365 - val_accuracy: 0.0533\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5625 - accuracy: 0.8266 - val_loss: 41.7182 - val_accuracy: 0.0533\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5845 - accuracy: 0.8097 - val_loss: 41.6050 - val_accuracy: 0.0533\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5838 - accuracy: 0.8240 - val_loss: 41.6315 - val_accuracy: 0.0533\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5167 - accuracy: 0.8423 - val_loss: 41.7318 - val_accuracy: 0.0533\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.5201 - accuracy: 0.8254 - val_loss: 41.7038 - val_accuracy: 0.0533\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4943 - accuracy: 0.8406 - val_loss: 41.5198 - val_accuracy: 0.0533\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.5346 - accuracy: 0.8072 - val_loss: 41.4611 - val_accuracy: 0.0533\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5478 - accuracy: 0.8259 - val_loss: 41.4633 - val_accuracy: 0.0533\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4908 - accuracy: 0.8421 - val_loss: 41.7047 - val_accuracy: 0.0533\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5299 - accuracy: 0.8362 - val_loss: 41.5422 - val_accuracy: 0.0533\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5263 - accuracy: 0.8296 - val_loss: 41.2872 - val_accuracy: 0.0533\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5476 - accuracy: 0.8242 - val_loss: 41.3893 - val_accuracy: 0.0533\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5156 - accuracy: 0.8085 - val_loss: 41.5013 - val_accuracy: 0.0533\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.5075 - accuracy: 0.8247 - val_loss: 41.5509 - val_accuracy: 0.0533\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.5205 - accuracy: 0.8186 - val_loss: 41.7924 - val_accuracy: 0.0533\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5392 - accuracy: 0.8323 - val_loss: 41.9074 - val_accuracy: 0.0533\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5338 - accuracy: 0.8105 - val_loss: 41.7116 - val_accuracy: 0.0533\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4597 - accuracy: 0.8471 - val_loss: 41.6880 - val_accuracy: 0.0400\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.6000 - accuracy: 0.8046 - val_loss: 41.8362 - val_accuracy: 0.0400\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5270 - accuracy: 0.8151 - val_loss: 41.9734 - val_accuracy: 0.0533\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5076 - accuracy: 0.8274 - val_loss: 41.8608 - val_accuracy: 0.0533\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.4972 - accuracy: 0.8283 - val_loss: 41.8447 - val_accuracy: 0.0533\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.4902 - accuracy: 0.8456 - val_loss: 42.0038 - val_accuracy: 0.0533\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4303 - accuracy: 0.8562 - val_loss: 42.2139 - val_accuracy: 0.0533\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4620 - accuracy: 0.8335 - val_loss: 42.2350 - val_accuracy: 0.0533\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4633 - accuracy: 0.8416 - val_loss: 42.2063 - val_accuracy: 0.0533\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4895 - accuracy: 0.8410 - val_loss: 42.1912 - val_accuracy: 0.0533\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4896 - accuracy: 0.8166 - val_loss: 42.1736 - val_accuracy: 0.0533\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4644 - accuracy: 0.8554 - val_loss: 42.2844 - val_accuracy: 0.0400\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.5351 - accuracy: 0.8166 - val_loss: 42.3949 - val_accuracy: 0.0533\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.4582 - accuracy: 0.8485 - val_loss: 42.3615 - val_accuracy: 0.0533\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4990 - accuracy: 0.8213 - val_loss: 42.2240 - val_accuracy: 0.0533\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4678 - accuracy: 0.8458 - val_loss: 42.2680 - val_accuracy: 0.0533\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4689 - accuracy: 0.8456 - val_loss: 42.5149 - val_accuracy: 0.0533\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.4777 - accuracy: 0.8470 - val_loss: 42.5528 - val_accuracy: 0.0533\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4747 - accuracy: 0.8395 - val_loss: 42.5583 - val_accuracy: 0.0533\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4573 - accuracy: 0.8463 - val_loss: 42.6110 - val_accuracy: 0.0400\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4527 - accuracy: 0.8601 - val_loss: 42.5525 - val_accuracy: 0.0400\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4275 - accuracy: 0.8664 - val_loss: 42.4499 - val_accuracy: 0.0533\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4847 - accuracy: 0.8357 - val_loss: 42.4163 - val_accuracy: 0.0533\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4401 - accuracy: 0.8555 - val_loss: 42.4096 - val_accuracy: 0.0533\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.4584 - accuracy: 0.8638 - val_loss: 42.5624 - val_accuracy: 0.0400\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 0.4426 - accuracy: 0.8676 - val_loss: 42.7402 - val_accuracy: 0.0400\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.5164 - accuracy: 0.8158 - val_loss: 42.8507 - val_accuracy: 0.0400\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4717 - accuracy: 0.8409 - val_loss: 42.9692 - val_accuracy: 0.0400\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4678 - accuracy: 0.8266 - val_loss: 42.8709 - val_accuracy: 0.0400\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4808 - accuracy: 0.8476 - val_loss: 42.7577 - val_accuracy: 0.0400\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4970 - accuracy: 0.8348 - val_loss: 42.8835 - val_accuracy: 0.0533\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4470 - accuracy: 0.8444 - val_loss: 43.0419 - val_accuracy: 0.0533\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4714 - accuracy: 0.8392 - val_loss: 43.0551 - val_accuracy: 0.0533\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4527 - accuracy: 0.8510 - val_loss: 42.9024 - val_accuracy: 0.0533\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4515 - accuracy: 0.8343 - val_loss: 42.8434 - val_accuracy: 0.0533\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4660 - accuracy: 0.8498 - val_loss: 42.9723 - val_accuracy: 0.0533\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4475 - accuracy: 0.8411 - val_loss: 43.0771 - val_accuracy: 0.0533\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4323 - accuracy: 0.8534 - val_loss: 43.1360 - val_accuracy: 0.0533\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.4783 - accuracy: 0.8367 - val_loss: 43.1526 - val_accuracy: 0.0533\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.3892 - accuracy: 0.8650 - val_loss: 43.3191 - val_accuracy: 0.0533\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4945 - accuracy: 0.8453 - val_loss: 43.4423 - val_accuracy: 0.0533\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.4334 - accuracy: 0.8539 - val_loss: 43.4058 - val_accuracy: 0.0533\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4411 - accuracy: 0.8636 - val_loss: 43.3942 - val_accuracy: 0.0533\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.3770 - accuracy: 0.8800 - val_loss: 43.5387 - val_accuracy: 0.0533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "ERKr1h7oUFhk",
        "outputId": "4a78e938-1c43-4fce-8242-e36c5394d4ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "def plot_model(history):\r\n",
        "  plt.plot(history.history['loss'])\r\n",
        "  plt.plot(history.history['val_loss'])\r\n",
        "  plt.title('Training vs Validation Loss')\r\n",
        "  plt.legend(['Training Loss','Validation Loss'],loc='lower right')\r\n",
        "  plt.show()\r\n",
        "  plt.plot(history.history['accuracy'])\r\n",
        "  plt.plot(history.history['val_accuracy'])\r\n",
        "  plt.title('Training vs Validation Accuracy')\r\n",
        "  plt.legend(['Training Accuracy','Validation Accuracy'],loc='lower right')\r\n",
        "  plt.show()\r\n",
        "    \r\n",
        "plot_model(history)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9AJDFiUriA",
        "outputId": "e35ff78a-b70b-482a-cef2-b2f325b17aaf"
      },
      "source": [
        "seed_text = \"I'm suffering in this dearth\"\r\n",
        "next_words = 50\r\n",
        "\r\n",
        "for _ in range(next_words):\r\n",
        "    # Create a token lists using tokenizer text sequences of the seed text\r\n",
        "    token_list = tk.texts_to_sequences([seed_text])[0]\r\n",
        "    \r\n",
        "    # Pre-pad the token list with the length of max_sequence_length-1\r\n",
        "    token_list_padded = pad_sequences([token_list], maxlen= max_sequence_length-1, padding= 'pre')\r\n",
        "    \r\n",
        "    # Predict the classe for the given token list \r\n",
        "    predicted = model.predict_classes(token_list_padded, verbose=0)\r\n",
        "\r\n",
        "    # Turn the token back into a word and add that to the seed text\r\n",
        "    output_word = \"\"\r\n",
        "    for word, index in tk.word_index.items():\r\n",
        "        if index == predicted:\r\n",
        "            output_word = word\r\n",
        "            break\r\n",
        "    seed_text += \" \" + output_word\r\n",
        "    \r\n",
        "print(seed_text)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I'm suffering in this dearth you may as well country he he did did did to price covetous where be go you i pray you not not barren of accusations accusations did covetous you he that fathers fathers please our himself please remain remain remain remain good to good you way for you that poor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaI2P4BUV0R9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}